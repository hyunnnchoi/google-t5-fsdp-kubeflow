apiVersion: v1
kind: Service
metadata:
  name: fsdp-t5-training-master
spec:
  selector:
    job-name: fsdp-t5-training-master
  ports:
    - protocol: TCP
      port: 29500  # PyTorch 기본 포트
      targetPort: 29500
  clusterIP: None  # Headless Service
---
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: fsdp-t5-training
spec:
  runPolicy:
    cleanPodPolicy: None
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          nodeSelector:
            kubernetes.io/hostname: xsailor-master
          containers:
          - name: pytorch
            image: potato4332/t5-fsdp:0.0.x-cache
            imagePullPolicy: IfNotPresent
            command:
              - "/bin/bash"
            args:
              - "-c"
              - "nsys profile --duration=1200 -o /result/t5-large-master python /workspace/t5-base.py --dataset_url 'https://public-nlp-datasets.s3.us-west-2.amazonaws.com/wikihowAll.csv' --model_name 't5-large' --num_samples 1500 --input_length 512 --output_length 150 --batch_size 1 --num_epochs 1 --learning_rate 0.002 --max_steps 50"
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: LOCAL_RANK
              value: "0"  # 마스터의 로컬 랭크
            - name: RANK
              value: "0"  # 마스터의 글로벌 랭크
            - name: WORLD_SIZE
              value: "4"  # 전체 프로세스 수
            - name: MASTER_ADDR
              value: "fsdp-t5-training-master-0"  # 마스터 Pod 이름
            - name: MASTER_PORT
              value: "29500"  # PyTorch 기본 포트
            resources:
              requests:
                cpu: 1
                nvidia.com/gpu: 1
              limits:
                cpu: 5
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /data
              name: tfjob-dataset
            - mountPath: /dev/shm
              name: shmdir
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: tfjob-dataset
            persistentVolumeClaim:
              claimName: tfjob-nfs-dataset-storage-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
    Worker:
      replicas: 3
      restartPolicy: Never
      template:
        spec:
          nodeSelector:
            kubernetes.io/hostname: xsailor-master
          containers:
          - name: pytorch
            image: potato4332/t5-fsdp:0.0.x-cache
            imagePullPolicy: IfNotPresent
            command:
              - "/bin/bash"
            args:
              - "-c"
              - "nsys profile --duration=1200 -o /result/t5-large-worker python /workspace/t5-base.py --dataset_url 'https://public-nlp-datasets.s3.us-west-2.amazonaws.com/wikihowAll.csv' --model_name 't5-large' --num_samples 1500 --input_length 512 --output_length 150 --batch_size 1 --num_epochs 1 --learning_rate 0.002 --max_steps 50"
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: LOCAL_RANK
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['local-rank']
            - name: RANK
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['rank']
            - name: WORLD_SIZE
              value: "4"  # 전체 프로세스 수
            - name: MASTER_ADDR
              value: "fsdp-t5-training-master-0"  # 마스터 Pod 이름
            - name: MASTER_PORT
              value: "29500"
            resources:
              requests:
                cpu: 1
                nvidia.com/gpu: 1
              limits:
                cpu: 5
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /data
              name: tfjob-dataset
            - mountPath: /dev/shm
              name: shmdir
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: tfjob-dataset
            persistentVolumeClaim:
              claimName: tfjob-nfs-dataset-storage-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
